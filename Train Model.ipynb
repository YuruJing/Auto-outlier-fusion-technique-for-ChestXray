{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a21d6982",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0ed4226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary libraries for training the model \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision \n",
    "from torchvision import transforms\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl # handle the complete traning phrase\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint # frequently stop the current weight\n",
    "from pytorch_lightning.loggers import TensorBoardLogger # enable to login the tensor board\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0025dd",
   "metadata": {},
   "source": [
    "## Image data Prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4055933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the file path\n",
    "def load_file(path):\n",
    "    return np.load(path).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d78dd4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation and transforms  \n",
    "train_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                      transforms.Normalize(0.0021,0.0010),\n",
    "                                      transforms.RandomAffine(degrees=(-5,5), translate=(0,0.05), scale=(0.9,1.1))])\n",
    "\n",
    "val_transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                    transforms.Normalize(0.0021, 0.0010)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f1f8bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create train and validation set\n",
    "train_set = torchvision.datasets.DatasetFolder(root=\"Outliers/train\",\n",
    "                                               loader=load_file, extensions=\"npy\", transform=train_transform)\n",
    "\n",
    "val_set = torchvision.datasets.DatasetFolder(root=\"Outliers/val\",\n",
    "                                             loader=load_file, extensions=\"npy\", transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4093b2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(val_set)):\n",
    "    if val_set[i][0].shape != torch.Size([1, 224, 224]):\n",
    "        print(f\"index: {i}  shape:{val_set[i][0].shape}\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e83c208e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Atelectasis': 0,\n",
       " 'Cardiomegaly': 1,\n",
       " 'Consolidation': 2,\n",
       " 'Edema': 3,\n",
       " 'Effusion': 4,\n",
       " 'Emphysema': 5,\n",
       " 'Fibrosis': 6,\n",
       " 'Hernia': 7,\n",
       " 'Infiltration': 8,\n",
       " 'Mass': 9,\n",
       " 'No Finding': 10,\n",
       " 'Nodule': 11,\n",
       " 'Pleural_Thickening': 12,\n",
       " 'Pneumothorax': 13}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels for each diseases\n",
    "train_set.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "98a4d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the data loader\n",
    "batch_size = 64\n",
    "nums_worker = 4\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, num_workers=nums_worker, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, num_workers=nums_worker, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ad8084",
   "metadata": {},
   "source": [
    "## Utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b7c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### deep generalized max-pooling\n",
    "'''Adjustment version from V. Christlein, L. Spranger, M. Seuret, A. Nicolaou, P. Kr√°l, A. Maier. \"Deep Generalized Max Pooling.\" arXiv preprint arXiv:1908.05040 (2019).'''\n",
    "\n",
    "class GMP(nn.Module):\n",
    "    def __init__(self, lamb=10**3): \n",
    "        super(GMP, self).__init__()\n",
    "        \n",
    "        self.lamb = nn.Parameter(lamb * torch.ones(1).cuda())\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, D, H, W = x.shape\n",
    "        N = H * W\n",
    "        identity = torch.eye(N).cuda()\n",
    "        # reshape x, s.t. we can use the gmp formulation as a global pooling operation\n",
    "        x = x.view(B, D, N)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        # compute the linear kernel\n",
    "        K = torch.bmm(x, x.permute(0, 2, 1))\n",
    "        # solve the linear system (K + lambda * I) * alpha = ones\n",
    "        A = K + self.lamb * identity\n",
    "        o = torch.ones(B, N, 1).cuda()\n",
    "        alphas = torch.linalg.solve(A, o)\n",
    "        alphas = alphas.view(B, 1, -1)        \n",
    "        xi = torch.bmm(alphas, x)\n",
    "        xi = xi.view(B, -1)\n",
    "        # L2 normalization\n",
    "        xi = nn.functional.normalize(xi)\n",
    "        \n",
    "        return xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62488417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "## Focal Loss function \n",
    "class FocalLoss(nn.modules.loss._WeightedLoss):\n",
    "    def __init__(self, device,weight=torch.tensor([1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.5,1.0,1.0,1.0]), gamma=2,reduction='mean'): # None\n",
    "        super(FocalLoss, self).__init__(weight,reduction=reduction)\n",
    "        self.gamma = gamma\n",
    "        self.device = device\n",
    "        self.weight = weight.to(self.device)\n",
    "\n",
    "    def forward(self, input, target):\n",
    "\n",
    "        ce_loss = F.cross_entropy(input, target,reduction=self.reduction,weight=self.weight) \n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1 - pt) ** self.gamma * ce_loss).mean()\n",
    "        return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c68fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Channel attention (SENet)\n",
    "'''Moskomule, 2019, https://github.com/moskomule/senet.pytorch'''\n",
    "\n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a5e804",
   "metadata": {},
   "outputs": [],
   "source": [
    "### spatial attention\n",
    "\n",
    "class Spatial_Attention_Module(nn.Module):\n",
    "    def __init__(self, k: int): # in paper best is k = 7\n",
    "        super(Spatial_Attention_Module, self).__init__()\n",
    "        self.avg_pooling = torch.mean\n",
    "        self.max_pooling = torch.max\n",
    "        # In order to keep the size of the front and rear images consistent\n",
    "        assert k in [3, 5, 7], \"kernel size = 1 + 2 * padding, so kernel size must be 3, 5, 7\"\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size = (k, k), stride = (1, 1), padding = ((k - 1) // 2, (k - 1) // 2),\n",
    "                              bias = False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # compress the C channel to 1 and keep the dimensions\n",
    "        avg_x = self.avg_pooling(x, dim = 1, keepdim = True)\n",
    "        max_x, _ = self.max_pooling(x, dim = 1, keepdim = True)\n",
    "        v = self.conv(torch.cat((max_x, avg_x), dim = 1))\n",
    "        v = self.sigmoid(v)\n",
    "        return x * v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa0e417",
   "metadata": {},
   "outputs": [],
   "source": [
    "### coordinate attention \n",
    "'''The following codes are from the paper, Coordinate Attention for Efficient Mobile Network Design\n",
    "Hou et al., 2021, https://github.com/houqb/CoordAttention'''\n",
    "\n",
    "class h_sigmoid(nn.Module):\n",
    "    def __init__(self, inplace=True):\n",
    "        super(h_sigmoid, self).__init__()\n",
    "        self.relu = nn.ReLU6(inplace=inplace)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(x + 3) / 6\n",
    "\n",
    "class h_swish(nn.Module):\n",
    "    def __init__(self, inplace=True):\n",
    "        super(h_swish, self).__init__()\n",
    "        self.sigmoid = h_sigmoid(inplace=inplace)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.sigmoid(x)\n",
    "\n",
    "class CoordAtt(nn.Module):\n",
    "    def __init__(self, inp, oup, reduction=32):\n",
    "        super(CoordAtt, self).__init__()\n",
    "        self.pool_h = nn.AdaptiveAvgPool2d((None, 1))\n",
    "        self.pool_w = nn.AdaptiveAvgPool2d((1, None))\n",
    "\n",
    "        mip = max(8, inp // reduction)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(inp, mip, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(mip)\n",
    "        self.act = h_swish()\n",
    "        \n",
    "        self.conv_h = nn.Conv2d(mip, oup, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv_w = nn.Conv2d(mip, oup, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        n,c,h,w = x.size()\n",
    "        x_h = self.pool_h(x)\n",
    "        x_w = self.pool_w(x).permute(0, 1, 3, 2)\n",
    "\n",
    "        y = torch.cat([x_h, x_w], dim=2)\n",
    "        y = self.conv1(y)\n",
    "        y = self.bn1(y)\n",
    "        y = self.act(y) \n",
    "        \n",
    "        x_h, x_w = torch.split(y, [h, w], dim=2)\n",
    "        x_w = x_w.permute(0, 1, 3, 2)\n",
    "\n",
    "        a_h = self.conv_h(x_h).sigmoid()\n",
    "        a_w = self.conv_w(x_w).sigmoid()\n",
    "\n",
    "        out = identity * a_w * a_h\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccef904",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the model to generate multi-head attention map\n",
    "class multi_att(nn.Module):\n",
    "    def __init__(self, inchannels=1, se_input=1, spatial_input=7, \n",
    "                 coord_input=1, coord_output=1, extract=False, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"), \n",
    "                outchannels=1):\n",
    "        super(multi_att, self).__init__()\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=inchannels, out_channels=1, kernel_size=1, stride=1, padding=0)\n",
    "#         self.conv3 = torch.nn.Conv1d(in_channels=inchannels, out_channels=1, kernel_size=1, stride=1, padding=0)\n",
    "        self.seatt = SELayer(se_input)\n",
    "        self.spatialatt = Spatial_Attention_Module(spatial_input)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.coordatt = CoordAtt(coord_input,coord_output)\n",
    "        \n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=3, out_channels=1, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        concate_data = torch.concat((self.seatt(x), self.spatialatt(x)), dim=1)\n",
    "        final_attention = torch.concat((self.sigmoid(concate_data), self.coordatt(x)), dim=1)\n",
    "        final_attention = self.conv2(final_attention)\n",
    "        \n",
    "        return final_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7b5591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_kfold(dataset, k_fold):\n",
    "    '''\n",
    "    Arguments:\n",
    "    dataset: the full dataset\n",
    "    k_fold: the number of cross-validation fold wants to split\n",
    "    \n",
    "    return:\n",
    "    train_list: all possible training set after split\n",
    "    test_list: all possible testing set after split\n",
    "    '''\n",
    "    # the total dataset \n",
    "    total_size = len(dataset)\n",
    "    # the proportion of the testing data set\n",
    "    prop = 1/k_fold\n",
    "    ## containing size for the validation each time (need to be integer)\n",
    "    vali_size = torch.round(torch.tensor(total_size * prop)) \n",
    "    vali_size = vali_size.to(torch.int)\n",
    "  \n",
    "    # starting split the test and train data sets\n",
    "    train_list = []\n",
    "    vali_list = []\n",
    "\n",
    "    for i in range(k_fold):\n",
    "        \n",
    "    ## splitting vali and train\n",
    "        ### get the splitting indices for training set \n",
    "        train_left = list(range(0,i*vali_size))\n",
    "        train_right = list(range(i*vali_size + vali_size, total_size))\n",
    "        train_indices = train_left + train_right\n",
    "        ### get the splitting indices for testing set\n",
    "        vali_indices = list(range(i*vali_size, i*vali_size + vali_size))\n",
    "    ## split the test and train data sets\n",
    "        train_set = torch.utils.data.dataset.Subset(dataset,train_indices)\n",
    "        vali_set = torch.utils.data.dataset.Subset(dataset,vali_indices)\n",
    "        print(\"The length of the training set is {}\".format(len(train_set)))\n",
    "        print(\"The length of the training set is {}\".format(len(vali_set)))\n",
    "        train_list.append(train_set)\n",
    "        vali_list.append(vali_set)\n",
    "\n",
    "    return train_list, vali_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2be8217",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc9859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the training model (deep generalized max-pooling version) \n",
    "class GMP_Model(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(GMP_Model, self).__init__()\n",
    "        \n",
    "        ## initialize the model\n",
    "        self.model = torchvision.models.resnet101(pretrained=True)\n",
    "        self.model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) # convert to 1 channel\n",
    "        # change self.model.avgpool = GMP()\n",
    "        self.model.fc = torch.nn.Linear(2048, 14)\n",
    "        \n",
    "        ## get the feature map before the prediction layer\n",
    "        self.feature_map = torch.nn.Sequential(*list(self.model.children())[:-2])\n",
    "        \n",
    "        ## model initialization and metrics\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-4)\n",
    "        self.loss_fn = FocalLoss()\n",
    "        \n",
    "        self.train_acc = torchmetrics.Accuracy()\n",
    "        self.val_acc = torchmetrics.Accuracy()\n",
    "        self.train_sep = torchmetrics.Specificity()#average='macro' #num_classes=14)\n",
    "        self.val_sep = torchmetrics.Specificity()#average='macro', num_classes=14)\n",
    "        self.train_f1 = torchmetrics.F1Score()\n",
    "        self.val_f1 = torchmetrics.F1Score()\n",
    "        #self.train_auc = torchmetrics.AUC(reorder=True)\n",
    "        #self.val_auc = torchmetrics.AUC(reorder=True)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        feature_map = self.feature_map(data)\n",
    "        gmp = GMP()\n",
    "        max_outs = gmp(feature_map) # change the avgpool into genralized max pooling \n",
    "        final_outs = self.model.fc(max_outs) # torch.flatten()\n",
    "        \n",
    "        return final_outs\n",
    "    \n",
    "    # training process\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_ray, label = batch\n",
    "        label = label.long()\n",
    "        pred = self(x_ray)\n",
    "        loss = self.loss_fn(pred, label) # compute loss\n",
    "        \n",
    "        # log (record the loss) log loss and batch accuracy\n",
    "        self.log(\"Train loss\", loss)\n",
    "        self.log(\"Step Train Acc\", self.train_acc(pred, label.int())) # torch sigmoid\n",
    "        self.log(\"Step Train Sep\", self.train_sep(pred, label.int()))\n",
    "        self.log(\"Step Train F1\", self.train_f1(pred, label.int()))\n",
    "        #self.log(\"Step Train AUC\", self.train_auc(pred, label.int()))\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    # compute the whole training set's metrics\n",
    "    def training_epoch_end(self, outs):\n",
    "        self.log(\"Train ACC\", self.train_acc.compute())\n",
    "        self.log(\"Train Sep\", self.train_sep.compute())\n",
    "        self.log(\"Train F1\", self.train_f1.compute())\n",
    "        #self.log(\"Train AUC\", self.train_auc.compute())\n",
    "        \n",
    "    # validation process\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_ray, label = batch\n",
    "        label = label.long()\n",
    "        pred = self(x_ray)\n",
    "        loss = self.loss_fn(pred, label)\n",
    "        \n",
    "        self.log(\"Val loss\", loss)\n",
    "        self.log(\"Step Val Acc\", self.val_acc(pred, label.int())) # torch sigmoid\n",
    "        self.log(\"Step Val Sep\", self.val_sep(pred, label.int()))\n",
    "        self.log(\"Step Val F1\", self.val_f1(pred, label.int()))\n",
    "        #self.log(\"Step Val AUC\", self.val_auc(pred, label.int()))\n",
    "        \n",
    "    # compute the whole validation's metrics\n",
    "    def validation_epoch_end(self, outs):\n",
    "        self.log(\"Val ACC\", self.val_acc.compute())\n",
    "        self.log(\"Val Sep\", self.val_sep.compute())\n",
    "        self.log(\"Val F1\", self.val_f1.compute())\n",
    "        #self.log(\"Val AUC\", self.val_auc.compute())\n",
    "        \n",
    "        \n",
    "    # return the list of all optimizers\n",
    "    def configure_optimizers(self):\n",
    "        return [self.optimizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e737e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the training process\n",
    "## creat the checkout callback to store checkpoints during training, store 10 best models based on validation accuracy)\n",
    "gmp = GMP_Model()\n",
    "checkpoint_callback = ModelCheckpoint(monitor=\"Val F1\",save_top_k=10, mode=\"max\")\n",
    "trainer = pl.Trainer(logger=TensorBoardLogger(save_dir=\"./logs_gmpbase\"), log_every_n_steps=1, \n",
    "                    callbacks=checkpoint_callback, \n",
    "                    max_epochs=30, gpus=1)\n",
    "trainer.fit(gmp, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958f4bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the training model \n",
    "class Self_multiatt_Model(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, inchannels, extract=False):\n",
    "        super(Self_multiatt_Model, self).__init__()\n",
    "        \n",
    "        ## initialize the model\n",
    "        self.model = torchvision.models.resnet101(pretrained=True)\n",
    "        self.multiatt = multi_att(inchannels=inchannels, extract=extract)\n",
    "        \n",
    "        ## change fully connected layer\n",
    "        self.model.fc = torch.nn.Linear(3, 14)\n",
    "        \n",
    "        ## get the feature map before the prediction layer\n",
    "        self.feature_map = torch.nn.Sequential(*list(self.model.children())[:-2])\n",
    "        \n",
    "        ## model initialization and metrics\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-4)\n",
    "        self.loss_fn = FocalLoss()\n",
    "        \n",
    "        self.train_acc = torchmetrics.Accuracy()\n",
    "        self.val_acc = torchmetrics.Accuracy()\n",
    "        self.train_sep = torchmetrics.Specificity()#average='macro' #num_classes=14)\n",
    "        self.val_sep = torchmetrics.Specificity()#average='macro', num_classes=14)\n",
    "        self.train_f1 = torchmetrics.F1Score()\n",
    "        self.val_f1 = torchmetrics.F1Score()\n",
    "        #self.train_auc = torchmetrics.AUC(reorder=True)\n",
    "        #self.val_auc = torchmetrics.AUC(reorder=True)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        attention_map = self.multiatt(data)\n",
    "        feature_map = self.feature_map(fattention_map)\n",
    "        gmp = GMP()\n",
    "        max_outs = gmp(feature_map) # change the avgpool into genralized max pooling \n",
    "        final_outs = self.model.fc(max_outs) # torch.flatten()\n",
    "        \n",
    "        return final_outs\n",
    "    \n",
    "    # training process\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_ray, label = batch\n",
    "        label = label.long()\n",
    "        pred = self(x_ray)\n",
    "        loss = self.loss_fn(pred, label) # compute loss\n",
    "        \n",
    "        # log (record the loss) log loss and batch accuracy\n",
    "        self.log(\"Train loss\", loss)\n",
    "        self.log(\"Step Train Acc\", self.train_acc(pred, label.int())) # torch sigmoid\n",
    "        self.log(\"Step Train Sep\", self.train_sep(pred, label.int()))\n",
    "        self.log(\"Step Train F1\", self.train_f1(pred, label.int()))\n",
    "        #self.log(\"Step Train AUC\", self.train_auc(pred, label.int()))\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    # compute the whole training set's metrics\n",
    "    def training_epoch_end(self, outs):\n",
    "        self.log(\"Train ACC\", self.train_acc.compute())\n",
    "        self.log(\"Train Sep\", self.train_sep.compute())\n",
    "        self.log(\"Train F1\", self.train_f1.compute())\n",
    "        #self.log(\"Train AUC\", self.train_auc.compute())\n",
    "        \n",
    "    # validation process\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_ray, label = batch\n",
    "        label = label.long()\n",
    "        pred = self(x_ray)\n",
    "        loss = self.loss_fn(pred, label)\n",
    "        \n",
    "        self.log(\"Val loss\", loss)\n",
    "        self.log(\"Step Val Acc\", self.val_acc(pred, label.int())) # torch sigmoid\n",
    "        self.log(\"Step Val Sep\", self.val_sep(pred, label.int()))\n",
    "        self.log(\"Step Val F1\", self.val_f1(pred, label.int()))\n",
    "        #self.log(\"Step Val AUC\", self.val_auc(pred, label.int()))\n",
    "        \n",
    "    # compute the whole validation's metrics\n",
    "    def validation_epoch_end(self, outs):\n",
    "        self.log(\"Val ACC\", self.val_acc.compute())\n",
    "        self.log(\"Val Sep\", self.val_sep.compute())\n",
    "        self.log(\"Val F1\", self.val_f1.compute())\n",
    "        #self.log(\"Val AUC\", self.val_auc.compute())\n",
    "        \n",
    "        \n",
    "    # return the list of all optimizers\n",
    "    def configure_optimizers(self):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615be151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the training process\n",
    "## creat the checkout callback to store checkpoints during training, store 10 best models based on validation accuracy)\n",
    "Self_multiatt = Self_multiatt_Model(1)\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "     monitor=\"Val F1\",\n",
    "     save_top_k=10, \n",
    "     mode=\"max\")\n",
    "\n",
    "# set the trainer\n",
    "gpus=1 \n",
    "trainer = pl.Trainer(logger=TensorBoardLogger(save_dir=\"./logs_self_multiatt\"), log_every_n_steps=1, \n",
    "                    callbacks=checkpoint_callback, \n",
    "                    max_epochs=30, gpus=gpus) # log every batch\n",
    "trainer.fit(Self_multiatt, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea71539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the training model for our proposed: add multi-head attention in the end\n",
    "class Multiatt_proposed(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self,inchannels=2048, extract=False):\n",
    "        super(Multiatt_proposed, self).__init__()\n",
    "        \n",
    "        ## initialize the model\n",
    "        self.model = torchvision.models.resnet101(pretrained=True)\n",
    "        self.model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) # convert to 1 channel\n",
    "        self.multiatt = multi_att(inchannels=inchannels, extract=extract)\n",
    "\n",
    "        self.model.fc = torch.nn.Linear(1, 14)\n",
    "        \n",
    "        ## get the feature map before the prediction layer\n",
    "        self.feature_map = torch.nn.Sequential(*list(self.model.children())[:-2])\n",
    "        \n",
    "        ## model initialization and metrics\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-4)\n",
    "        self.loss_fn = FocalLoss()\n",
    "        \n",
    "        self.train_acc = torchmetrics.Accuracy()\n",
    "        self.val_acc = torchmetrics.Accuracy()\n",
    "        self.train_sep = torchmetrics.Specificity()#average='macro' #num_classes=14)\n",
    "        self.val_sep = torchmetrics.Specificity()#average='macro', num_classes=14)\n",
    "        self.train_f1 = torchmetrics.F1Score()\n",
    "        self.val_f1 = torchmetrics.F1Score()\n",
    "        #self.train_auc = torchmetrics.AUC(reorder=True)\n",
    "        #self.val_auc = torchmetrics.AUC(reorder=True)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        feature_map = self.feature_map(data) # output feature \n",
    "        multi_attention = self.multiatt(feature_map) # use multi-head attention\n",
    "        gmp = GMP()\n",
    "        max_outs = gmp(multi_attention) # change the avgpool into genralized max pooling \n",
    "        final_outs = self.model.fc(max_outs) # torch.flatten()\n",
    "        \n",
    "        return final_outs\n",
    "    \n",
    "    # training process\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_ray, label = batch\n",
    "        label = label.long()\n",
    "        pred = self(x_ray)\n",
    "        loss = self.loss_fn(pred, label) # compute loss\n",
    "        \n",
    "        # log (record the loss) log loss and batch accuracy\n",
    "        self.log(\"Train loss\", loss)\n",
    "        self.log(\"Step Train Acc\", self.train_acc(pred, label.int())) # torch sigmoid\n",
    "        self.log(\"Step Train Sep\", self.train_sep(pred, label.int()))\n",
    "        self.log(\"Step Train F1\", self.train_f1(pred, label.int()))\n",
    "        #self.log(\"Step Train AUC\", self.train_auc(pred, label.int()))\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    # compute the whole training set's metrics\n",
    "    def training_epoch_end(self, outs):\n",
    "        self.log(\"Train ACC\", self.train_acc.compute())\n",
    "        self.log(\"Train Sep\", self.train_sep.compute())\n",
    "        self.log(\"Train F1\", self.train_f1.compute())\n",
    "        #self.log(\"Train AUC\", self.train_auc.compute())\n",
    "        \n",
    "    # validation process\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_ray, label = batch\n",
    "        label = label.long()\n",
    "        pred = self(x_ray)\n",
    "        loss = self.loss_fn(pred, label)\n",
    "        \n",
    "        self.log(\"Val loss\", loss)\n",
    "        self.log(\"Step Val Acc\", self.val_acc(pred, label.int())) # torch sigmoid\n",
    "        self.log(\"Step Val Sep\", self.val_sep(pred, label.int()))\n",
    "        self.log(\"Step Val F1\", self.val_f1(pred, label.int()))\n",
    "        #self.log(\"Step Val AUC\", self.val_auc(pred, label.int()))\n",
    "        \n",
    "    # compute the whole validation's metrics\n",
    "    def validation_epoch_end(self, outs):\n",
    "        self.log(\"Val ACC\", self.val_acc.compute())\n",
    "        self.log(\"Val Sep\", self.val_sep.compute())\n",
    "        self.log(\"Val F1\", self.val_f1.compute())\n",
    "        #self.log(\"Val AUC\", self.val_auc.compute())\n",
    "        \n",
    "        \n",
    "    # return the list of all optimizers\n",
    "    def configure_optimizers(self):\n",
    "        return [self.optimizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f938af10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the training process\n",
    "## creat the checkout callback to store checkpoints during training, store 10 best models based on validation accuracy)\n",
    "multiatt_prop = Multiatt_proposed(2048)\n",
    "\n",
    "# set the trainer\n",
    "gpus=1\n",
    "\n",
    "trainer = pl.Trainer(logger=TensorBoardLogger(save_dir=\"./logs_proposed_multiatt\"), log_every_n_steps=1, \n",
    "                    callbacks=checkpoint_callback, \n",
    "                    max_epochs=6, gpus=gpus) # log every batch\n",
    "trainer.fit(multiatt_prop, train_loader, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
